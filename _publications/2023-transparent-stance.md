---
title: "Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions"
collection: publications
permalink: /publication/2023-transparent-stance
excerpt: 'This paper tackles the transparency issue in online content moderation, using Wikipedia as a case study where moderation decisions are publicly discussed. The study introduces a multilingual dataset from Wikipedia editor discussions, demonstrating that combining editor stance and policy reasoning can be accurately predicted, contributing to increased transparency in content moderation.'
date: 2023-12-10
venue: 'EMNLP 2023'
paperurl: 'https://arxiv.org/pdf/2310.05779.pdf'
citation: 'Kaffee, L. A., Arora, A., & Augenstein, I. (2023). Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions. In EMNLP 2023.'
---
The moderation of content on online platforms is usually non-transparent. On Wikipedia, however, this discussion is carried out publicly and the editors are encouraged to use the content moderation policies as explanations for making moderation decisions. Currently, only a few comments explicitly mention those policies -- 20% of the English ones, but as few as 2% of the German and Turkish comments. To aid in this process of understanding how content is moderated, we construct a novel multilingual dataset of Wikipedia editor discussions along with their reasoning in three languages. The dataset contains the stances of the editors (keep, delete, merge, comment), along with the stated reason, and a content moderation policy, for each edit decision. We demonstrate that stance and corresponding reason (policy) can be predicted jointly with a high degree of accuracy, adding transparency to the decision-making process. We release both our joint prediction models and the multilingual content moderation dataset for further research on automated transparent content moderation.

[Full paper here](https://arxiv.org/pdf/2310.05779.pdf)